{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17121,"status":"ok","timestamp":1702098925251,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"LGhs1TY5vdEv","outputId":"7f40fe34-3e9b-4a8c-ac59-15508a40a8fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting topojson\n","  Downloading topojson-1.7-py2.py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n","Requirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.14.0)\n","Requirement already satisfied: pyproj in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Collecting mgwr\n","  Downloading mgwr-2.2.0-py2.py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from topojson) (1.23.5)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from topojson) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from topojson) (23.2)\n","Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.5)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n","Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.7.0)\n","Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium) (2.31.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj) (2023.11.17)\n","Requirement already satisfied: scipy>=0.11 in /usr/local/lib/python3.10/dist-packages (from mgwr) (1.11.4)\n","Collecting libpysal>=4.0.0 (from mgwr)\n","  Downloading libpysal-4.9.2-py3-none-any.whl (2.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting spglm>=1.0.6 (from mgwr)\n","  Downloading spglm-1.1.0-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting spreg (from mgwr)\n","  Downloading spreg-1.4.2-py3-none-any.whl (331 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.8/331.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n","Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (8.1.7)\n","Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (67.7.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium) (2.1.3)\n","Requirement already satisfied: beautifulsoup4>=4.10 in /usr/local/lib/python3.10/dist-packages (from libpysal>=4.0.0->mgwr) (4.11.2)\n","Requirement already satisfied: platformdirs>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from libpysal>=4.0.0->mgwr) (4.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (2.0.7)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from spreg->mgwr) (1.2.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.10->libpysal>=4.0.0->mgwr) (2.5)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->spreg->mgwr) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->spreg->mgwr) (3.2.0)\n","Installing collected packages: topojson, libpysal, spreg, spglm, mgwr\n","Successfully installed libpysal-4.9.2 mgwr-2.2.0 spglm-1.1.0 spreg-1.4.2 topojson-1.7\n"]}],"source":["!pip install topojson geopandas folium pyproj mgwr"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5436,"status":"ok","timestamp":1702098930666,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"toKiu_5PeZfX"},"outputs":[],"source":["import geopandas as gpd\n","import pandas as pd\n","import numpy as np\n","import shapely\n","import topojson as tp\n","import plotly.express as px\n","import folium\n","from folium.plugins import MarkerCluster\n","import io\n","import base64\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import pyproj\n","import geopandas as gpd\n","import mgwr\n","import seaborn as sns\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=DeprecationWarning)"]},{"cell_type":"markdown","metadata":{"id":"LZEycEKHvLYx"},"source":["We load merged_geo_df.csv"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129653,"status":"ok","timestamp":1702099060312,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"p6TG3Igt2eBK","outputId":"9574323c-facd-4bcd-bfe9-c90956a648a3","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","   id       code                                           geometry  \\\n","0 NaN  E05000650  POLYGON ((370295 414672, 372394 411758, 370557...   \n","1 NaN  E05000651  POLYGON ((375017 414993, 375017 414809, 375709...   \n","2 NaN  E05000652  POLYGON ((373586 410473, 375160 410817, 375327...   \n","3 NaN  E05000653  POLYGON ((372394 411758, 370295 414672, 373276...   \n","4 NaN  E05000654  POLYGON ((370557 411414, 372394 411758, 373157...   \n","\n","          areaName      cx      cy  detached  semiDetached  terraced  \\\n","0    Astley Bridge  370732  412836  0.966641      1.564969  1.334971   \n","1         Bradshaw  374479  412684  1.370174      1.727901  0.074846   \n","2       Breightmet  374513  409534 -0.194186      2.489098  1.312189   \n","3    Bromley Cross  371904  414137  2.609219      0.911970  1.104304   \n","4  Crompton Bolton  371830  410799 -0.455505      0.602654  3.717106   \n","\n","      flats  ...       oil      wood     solid  renewable  communal  \\\n","0 -0.145641  ... -0.442458 -0.202465 -0.199341  -0.625874 -0.061271   \n","1 -0.412695  ... -0.282163 -0.081905 -0.360519  -0.100766 -0.226772   \n","2  0.096571  ... -0.495890 -0.202465 -0.118752  -0.520853 -0.216428   \n","3 -0.299663  ... -0.451363 -0.443586 -0.441108  -0.363320 -0.247459   \n","4  0.838113  ... -0.402384 -0.564146 -0.199341  -0.468342  0.145606   \n","\n","   other_heating  2plusNonRenewable  2plusRenewable    female      male  \n","0       0.449533           1.007348       -0.197565  1.356926  1.369929  \n","1      -0.218830           0.461422       -0.047647  0.839560  0.765981  \n","2       0.989365           1.699741       -0.497401  1.458793  1.375185  \n","3      -0.321655           0.960744       -0.197565  1.296905  1.215329  \n","4       1.811966           2.092542       -0.722278  2.041675  2.167893  \n","\n","[5 rows x 88 columns]\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","file_path = '/content/drive/My Drive/City Masters/Thesis/datasets for thesis/merged_geo_df.csv'\n","df = pd.read_csv(file_path)\n","print(df.head())\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1702099060313,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"Jmv5XXtnum_L","outputId":"4ae1035b-11f1-4b8e-fd02-bc7064f446d2","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["      id       code                                           geometry  \\\n","0    NaN  E05000650  POLYGON ((370295 414672, 372394 411758, 370557...   \n","1    NaN  E05000651  POLYGON ((375017 414993, 375017 414809, 375709...   \n","2    NaN  E05000652  POLYGON ((373586 410473, 375160 410817, 375327...   \n","3    NaN  E05000653  POLYGON ((372394 411758, 370295 414672, 373276...   \n","4    NaN  E05000654  POLYGON ((370557 411414, 372394 411758, 373157...   \n","...   ..        ...                                                ...   \n","7624 NaN  W05001796  POLYGON ((353864 205106, 352671 203936, 353148...   \n","7625 NaN  W05001797  POLYGON ((353220 194117, 353029 193819, 352170...   \n","7626 NaN  W05001798  POLYGON ((349857 212516, 350763 213387, 351956...   \n","7627 NaN  W05001799  POLYGON ((347019 188542, 347043 188542, 347591...   \n","7628 NaN  W05001800  POLYGON ((352767 215154, 355271 214374, 355294...   \n","\n","                    areaName      cx      cy  detached  semiDetached  \\\n","0              Astley Bridge  370732  412836  0.966641      1.564969   \n","1                   Bradshaw  374479  412684  1.370174      1.727901   \n","2                 Breightmet  374513  409534 -0.194186      2.489098   \n","3              Bromley Cross  371904  414137  2.609219      0.911970   \n","4            Crompton Bolton  371830  410799 -0.455505      0.602654   \n","...                      ...     ...     ...       ...           ...   \n","7624               St Arvans  352198  199550 -0.499947     -1.071214   \n","7625            St Kingsmark  352672  195165 -0.233295     -1.103037   \n","7626      Town Monmouthshire  350804  212770 -1.186132     -1.072487   \n","7627  West End Monmouthshire  347557  187547 -1.239463     -0.704618   \n","7628                 Wyesham  353180  213205 -0.835929     -0.766990   \n","\n","      terraced     flats  ...       oil      wood     solid  renewable  \\\n","0     1.334971 -0.145641  ... -0.442458 -0.202465 -0.199341  -0.625874   \n","1     0.074846 -0.412695  ... -0.282163 -0.081905 -0.360519  -0.100766   \n","2     1.312189  0.096571  ... -0.495890 -0.202465 -0.118752  -0.520853   \n","3     1.104304 -0.299663  ... -0.451363 -0.443586 -0.441108  -0.363320   \n","4     3.717106  0.838113  ... -0.402384 -0.564146 -0.199341  -0.468342   \n","...        ...       ...  ...       ...       ...       ...        ...   \n","7624 -0.940373 -0.657391  ...  1.276265  0.641457  0.928904   0.109277   \n","7625 -1.059978 -0.648697  ... -0.460269 -0.443586 -0.360519  -0.520853   \n","7626 -0.581558 -0.277305  ... -0.420195 -0.564146 -0.441108  -0.625874   \n","7627 -0.876299 -0.477285  ... -0.491437 -0.564146 -0.360519  -0.678385   \n","7628 -0.816496 -0.574170  ... -0.255447 -0.202465 -0.521697  -0.468342   \n","\n","      communal  other_heating  2plusNonRenewable  2plusRenewable    female  \\\n","0    -0.061271       0.449533           1.007348       -0.197565  1.356926   \n","1    -0.226772      -0.218830           0.461422       -0.047647  0.839560   \n","2    -0.216428       0.989365           1.699741       -0.497401  1.458793   \n","3    -0.247459      -0.321655           0.960744       -0.197565  1.296905   \n","4     0.145606       1.811966           2.092542       -0.722278  2.041675   \n","...        ...            ...                ...             ...       ...   \n","7624 -0.268147      -0.475892          -1.096465        0.027312 -1.297111   \n","7625 -0.299178      -0.732955          -1.402716       -0.797237 -1.258224   \n","7626 -0.247459      -0.681543          -1.309509       -1.172032 -1.240049   \n","7627 -0.299178      -0.553011          -1.555841       -1.097073 -1.269637   \n","7628 -0.195740      -0.655836          -1.176356       -0.947155 -1.226100   \n","\n","          male  \n","0     1.369929  \n","1     0.765981  \n","2     1.375185  \n","3     1.215329  \n","4     2.167893  \n","...        ...  \n","7624 -1.298566  \n","7625 -1.251704  \n","7626 -1.250390  \n","7627 -1.253018  \n","7628 -1.216229  \n","\n","[7629 rows x 88 columns]\n"]}],"source":["print(df)"]},{"cell_type":"markdown","metadata":{"id":"Ake_PM7ovLY1"},"source":["We use the same function that converts British National Grid (BNG) coordinates to WGS84 latitude and longitude coordinates by using the pyproj library to define a transformation from the BNG system (EPSG:27700) to the global latitude-longitude system (EPSG:4326). The function bng_to_latlng_vectorized applies this transformation to easting and northing coordinates in a DataFrame, resulting in new columns for latitude and longitude. This is useful for mapping and spatial analysis in the ML and regression models."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1702099060313,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"MA_2QdE6v79r"},"outputs":[],"source":["from pyproj import Transformer\n","\n","def bng_to_latlng_vectorized(easting, northing):\n","    # Create a transformer object for BNG (EPSG:27700) to WGS84 (EPSG:4326)\n","    transformer = Transformer.from_crs('epsg:27700', 'epsg:4326', always_xy=True)\n","    # Transform the coordinates\n","    lon, lat = transformer.transform(easting, northing)\n","    return lat, lon\n","\n","# Convert coordinates for the entire DataFrame\n","df['latitude'], df['longitude'] = bng_to_latlng_vectorized(df['cx'], df['cy'])"]},{"cell_type":"markdown","metadata":{"id":"4GfA1icrvLY2"},"source":["The code cell performs correlation analysis on the merged_geo_df dataset. It starts by selecting a target variable ('vGood') and identifying columns to exclude from the analysis. The correlation matrix for the remaining features is calculated and then visualized with a heatmap. It then focuses on the upper triangle of this matrix, identifying features with high correlation (above 0.90) and marking them for removal to reduce multicollinearity. Once that's done the features get dropped, and a new correlation matrix is recalculated and visualized. This process helps in understanding the relationships between features and refines the dataset by removing highly correlated variables to avoid multicollinearity."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1SpzvtdVfIlSPDO27G-85tynSAjkFm1zO"},"executionInfo":{"elapsed":34375,"status":"ok","timestamp":1702099094680,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"C_1VawSbvLY2","outputId":"fead363a-e80f-454e-e183-472f3532d041"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Assuming your main dataframe is df\n","target_df = df[['vGood']]\n","columns_to_exclude = ['vGood', 'good', 'fair', 'bad', 'vBad', 'id', 'code', 'geometry', 'areaName', 'cx', 'cy', 'latitude', 'longitude']\n","\n","# First, filter out the columns you want to exclude\n","features_df = df.drop(columns=columns_to_exclude)\n","\n","# Calculate the correlation matrix\n","corr_matrix = features_df.corr().abs()\n","\n","# Plot initial correlation matrix\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n","plt.title(\"Initial Correlation Matrix\")\n","plt.show()\n","\n","# Select upper triangle of correlation matrix\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n","\n","# Find index of feature columns with correlation greater than 0.90\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n","\n","# Create a mask for highlighting features to drop\n","mask = upper.applymap(lambda x: x > 0.90)\n","\n","# Plot the upper triangle of the correlation matrix with highlighted features to drop\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(upper, cmap='coolwarm', annot=True, mask=mask)\n","plt.title(\"Features to Drop (Correlation > 0.90)\")\n","plt.show()\n","\n","# Drop features\n","features_df.drop(columns=to_drop, inplace=True)\n","\n","# Recalculate the correlation matrix\n","new_corr_matrix = features_df.corr().abs()\n","\n","# Plot final correlation matrix\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(new_corr_matrix, annot=True, cmap='coolwarm')\n","plt.title(\"Final Correlation Matrix After Dropping Features\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"vXmtsA8qvLY3"},"source":["Now we employ the LassoCV method from Scikit-Learn to perform feature selection on the remaining variables. We start by defining X as the feature set and y as the target variable. It then initializes a LassoCV model with 5-fold cross-validation, a range of alpha values which is the regularization strength, and a high iteration count for fitting. After fitting is complete, we extract the coefficients associated with each feature. LassoCV has the ability to reduce the less important feature coefficients to zero. This allows us to select features with non-zero coefficients as the most relevant for predicting the target variable. We then finish by printing the remaining variables after the rest has been filtered."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":676,"status":"ok","timestamp":1702099095341,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"CXLNtXKTvLY3","outputId":"d3309cf4-8919-4450-e7b6-406418999158","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Selected features: Index(['detached', 'semiDetached', 'flats', 'sharedHouse', 'conversion',\n","       'commercial', 'caravan', 'dep0', 'dep1', 'management', 'professional',\n","       'admin', 'popDensity', 'level3', 'L8_L9', 'L15', 'v0', 'v2', 'v3plus',\n","       'ABBangladeshi', 'ABChinese', 'ABIndian', 'ABPakistani', 'ABAsian',\n","       'BBAfrican', 'BBCaribbean', 'whiteAndAsian', 'whiteAndBlackAfrican',\n","       'multiple', 'wBritish', 'wIrish', 'wRoma', 'wOther', 'other_ethnic',\n","       'none_heating', 'bottledGas', 'elec', 'oil', 'wood', 'solid',\n","       'communal', 'other_heating', '2plusRenewable'],\n","      dtype='object')\n"]}],"source":["from sklearn.linear_model import LassoCV\n","\n","X = (features_df)\n","\n","# Target variable\n","y = target_df.values.ravel()\n","\n","# Increase the range of alphas and the number of iterations\n","lasso = LassoCV(cv=5, random_state=0, max_iter=10000, alphas=10**np.linspace(-4, -0.5, 100)).fit(X, y)\n","# Get the feature names\n","feature_names = features_df.columns\n","\n","# Extract the coefficients and set a threshold to select features\n","lasso_coef = lasso.coef_\n","selected_features = feature_names[lasso_coef != 0]\n","\n","print(\"Selected features:\", selected_features)\n"]},{"cell_type":"markdown","metadata":{"id":"ph7tzMnMvLY4"},"source":["Now we use the Random Forest Regressor to identify and rank the most important features in a dataset for predicting a target variable. Starting by selecting features identified as significant by the previous LASSO model. A Random Forest Regressor is then trained with these features and the feature importances are extracted and sorted in descending order. The code defines a variable top_n_features to specify the number of top features to be displayed (set to 10) and prints out these top features along with their importance scores."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20012,"status":"ok","timestamp":1702099115348,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"AlK7NN5yvLY5","outputId":"58459de3-d8f2-4556-94ac-3b330475aea3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Top 10 features based on Random Forest after pruning:\n","1. Feature 'professional' (Importance: 0.23601043922388146)\n","2. Feature 'management' (Importance: 0.22146719602578438)\n","3. Feature 'v0' (Importance: 0.11783174590431054)\n","4. Feature 'dep1' (Importance: 0.10012572041877037)\n","5. Feature 'wBritish' (Importance: 0.058459410433690455)\n","6. Feature 'semiDetached' (Importance: 0.03430861939738077)\n","7. Feature 'level3' (Importance: 0.025058004574711093)\n","8. Feature 'whiteAndAsian' (Importance: 0.021364857438531986)\n","9. Feature 'L8_L9' (Importance: 0.021052358365104922)\n","10. Feature 'L15' (Importance: 0.014187575396499568)\n"]}],"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","# Filter the features DataFrame to only include selected features from LASSO\n","X_selected = features_df[selected_features]\n","\n","# Train a Random Forest Regressor on the selected features\n","forest = RandomForestRegressor(random_state=42)\n","forest.fit(X_selected, y)\n","\n","# Get feature importances from the Random Forest model\n","importances = forest.feature_importances_\n","\n","# Sort the feature importances\n","indices = np.argsort(importances)[::-1]\n","\n","# Define the number of top features to print\n","top_n_features = 10 # Set this to the number of features you want to include\n","\n","# Print the top feature importances\n","print(f\"Top {top_n_features} features based on Random Forest after pruning:\")\n","for f in range(top_n_features):\n","    # Check if the number of features is less than top_n_features\n","    if f < len(indices):\n","        print(f\"{f + 1}. Feature '{X_selected.columns[indices[f]]}' (Importance: {importances[indices[f]]})\")\n","    else:\n","        break\n"]},{"cell_type":"markdown","metadata":{"id":"6kLDAAp5vLY5"},"source":["Now for the GWR model, the process begins by preparing the data, including extracting relevant features and converting them to numpy arrays for analysis. The core of the script utilizes Optuna, a hyperparameter optimization framework, to find the best settings for the GWR model. It optimizes kernel type and model family (Gaussian, Poisson, or Binomial) by minimizing the Akaike Information Criterion (AIC), a measure balancing model fit and complexity. After running a specified number of trials, we identify the best kernel type and family. Then, the optimal parameters are used to construct the final GWR model. The model, which accounts for spatial variability in data by adjusting relationships across different geographic locations, is then fitted to the data, with results  providing localized insights which will be transposed on the UK map. The start and end times of the Optuna study is also recorded, for efficiency records."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8969,"status":"ok","timestamp":1702099124301,"user":{"displayName":"Faiq Hilman","userId":"02394852468598823244"},"user_tz":0},"id":"dJMQwp12wPqq","outputId":"2e9a285b-fe23-415b-8056-0b7e63bad939"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.0-py3-none-any.whl (230 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog (from optuna)\n","  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n","Installing collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.0 alembic-1.13.0 colorlog-6.8.0 optuna-3.4.0\n"]}],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"SMaOVKKEFbFt","scrolled":true,"outputId":"048908a5-7397-474c-f6d1-c4c61efc807f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 05:18:43,136] A new study created in memory with name: no-name-6d49900b-aaf6-4bd7-9868-0f5295276970\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 118.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 05:33:57,015] Trial 0 finished with value: 2964.41514107883 and parameters: {'kernel': 'bisquare', 'family': 'Poisson'}. Best is trial 0 with value: 2964.41514107883.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 63.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 05:49:51,630] Trial 1 finished with value: 11024.05418741779 and parameters: {'kernel': 'exponential', 'family': 'Binomial'}. Best is trial 0 with value: 2964.41514107883.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 63.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 06:05:04,551] Trial 2 finished with value: 11024.05418741779 and parameters: {'kernel': 'exponential', 'family': 'Binomial'}. Best is trial 0 with value: 2964.41514107883.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 63.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 06:17:51,178] Trial 3 finished with value: -34295.99479375255 and parameters: {'kernel': 'exponential', 'family': 'Gaussian'}. Best is trial 3 with value: -34295.99479375255.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 63.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 06:32:55,939] Trial 4 finished with value: 995.8416029416328 and parameters: {'kernel': 'exponential', 'family': 'Poisson'}. Best is trial 3 with value: -34295.99479375255.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 118.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 06:47:08,760] Trial 5 finished with value: 12986.703556568744 and parameters: {'kernel': 'bisquare', 'family': 'Binomial'}. Best is trial 3 with value: -34295.99479375255.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 63.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 07:02:17,898] Trial 6 finished with value: 995.8416029416328 and parameters: {'kernel': 'exponential', 'family': 'Poisson'}. Best is trial 3 with value: -34295.99479375255.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 63.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 07:17:19,331] Trial 7 finished with value: 1051.905491576354 and parameters: {'kernel': 'gaussian', 'family': 'Poisson'}. Best is trial 3 with value: -34295.99479375255.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 118.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 07:29:36,905] Trial 8 finished with value: -36806.50211064709 and parameters: {'kernel': 'bisquare', 'family': 'Gaussian'}. Best is trial 8 with value: -36806.50211064709.\n"]},{"output_type":"stream","name":"stdout","text":["Optuna trial bandwidth: 118.0\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-12-09 07:41:50,874] Trial 9 finished with value: -36806.50211064709 and parameters: {'kernel': 'bisquare', 'family': 'Gaussian'}. Best is trial 8 with value: -36806.50211064709.\n"]}],"source":["from mgwr.gwr import GWR\n","from mgwr.sel_bw import Sel_BW\n","import spglm.family\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error, r2_score\n","import optuna\n","import time\n","\n","\n","# Remove non-numeric and duplicate columns\n","selected_features = ['professional', 'management', 'v0', 'dep1','wBritish', 'semiDetached', 'level3' ,'whiteAndAsian'\n","                     ,'L8_L9', 'L15']\n","geo_columns = ['latitude', 'longitude']\n","target_column = 'vGood'\n","\n","# Create a new DataFrame with the selected features, geographic columns, and target\n","model_df = df[selected_features + geo_columns + [target_column]]\n","\n","# Convert to numpy arrays\n","X = np.array(model_df[selected_features])\n","y = np.array(model_df[target_column]).reshape((-1, 1))\n","coords = np.array(model_df[geo_columns])\n","\n","# Define the objective function for Optuna\n","def objective(trial):\n","    # Hyperparameters to be optimized\n","    kernel_type = trial.suggest_categorical('kernel', ['bisquare', 'gaussian', 'exponential'])\n","    family_type = trial.suggest_categorical('family', ['Gaussian', 'Poisson', 'Binomial'])\n","\n","    # Select model family\n","    if family_type == 'Gaussian':\n","        model_family = spglm.family.Gaussian()\n","    elif family_type == 'Poisson':\n","        model_family = spglm.family.Poisson()\n","    elif family_type == 'Binomial':\n","        model_family = spglm.family.Binomial()\n","\n","    # Bandwidth selection\n","    bw = Sel_BW(coords, y, X, fixed=False, kernel=kernel_type)\n","    gwr_bw = bw.search()\n","    print(f\"Optuna trial bandwidth: {gwr_bw}\")\n","\n","    # Create and fit GWR model\n","    model = GWR(coords, y, X, bw=gwr_bw, family=model_family, fixed=False, kernel=kernel_type)\n","    results = model.fit()\n","\n","    # Return the metric to optimize, e.g., AIC\n","    return results.aic\n","\n","# Start the timer\n","start_time = time.time()\n","\n","# Create an Optuna study and optimize the objective function\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=20)  # Adjust the number of trials as necessary\n","\n","# Stop the timer\n","end_time = time.time()\n","\n","# Calculate the duration\n","duration = end_time - start_time\n","print(f\"Total duration for Optuna optimization: {duration} seconds\")\n","\n","# Output the best hyperparameters\n","best_kernel = study.best_params['kernel']\n","best_family = study.best_params['family']\n","print('Best kernel:', best_kernel)\n","print('Best family:', best_family)\n","\n","# Create the final GWR model using the best parameters\n","if best_family == 'Gaussian':\n","    final_family = spglm.family.Gaussian()\n","elif best_family == 'Poisson':\n","    final_family = spglm.family.Poisson()\n","elif best_family == 'Binomial':\n","    final_family = spglm.family.Binomial()\n","\n","bw = Sel_BW(coords, y, X, fixed=False, kernel=best_kernel)\n","gwr_bw = bw.search()\n","print(f\"Final selected bandwidth: {gwr_bw}\")\n","gwr_model = GWR(coords, y, X, bw=gwr_bw, family=final_family, fixed=False, kernel=best_kernel)\n","gwr_results = gwr_model.fit()\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"es0JBo4dvLY6"},"source":["Now we'll extract the local parameters of each feature used in the GWR model, and we will transpose this on the map to analyze how the features vary spatially."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4A60-S9vLY7"},"outputs":[],"source":["# Extract local parameter estimates\n","local_params = gwr_results.params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EpG5IdIyvLY7"},"outputs":[],"source":["# Create a DataFrame for coordinates\n","df_coords = pd.DataFrame(coords, columns=['latitude', 'longitude'])\n","\n","# Set up the matplotlib figure\n","fig, axes = plt.subplots(4, 3, figsize=(15, 20))  # 4 rows, 3 columns\n","fig.subplots_adjust(hspace=0.4, wspace=0.4)  # Adjust horizontal and vertical spaces\n","\n","# Iterate over features and plot\n","for i, feature in enumerate(selected_features):\n","    row = i // 3  # Determine the row index\n","    col = i % 3   # Determine the column index\n","    ax = axes[row, col]\n","\n","    # Add the coefficients for the current feature\n","    df_coords['coefficient'] = local_params[:, i + 1]  # +1 to skip intercept\n","\n","    # Plot using seaborn on the specified subplot axis\n","    sns.scatterplot(data=df_coords, x='longitude', y='latitude', hue='coefficient', palette='BrBG', ax=ax)\n","    ax.set_title(f\"Coefficient for '{feature}'\")\n","    ax.set_xlabel('Longitude')\n","    ax.set_ylabel('Latitude')\n","\n","# If the number of features is not a multiple of 3, hide the empty subplots\n","for j in range(i + 1, 12):\n","    fig.delaxes(axes[j // 3, j % 3])\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"lwQEkesjvLY8"},"source":["Now the results of the GWR model is extracted below, focusing on various scalar and array metrics. A dictionary is created to store scalar results like AIC Score and Residual Variance. For Gaussian models, it also includes R-squared and Adjusted R-squared metrics, plus a new DataFrame of Local R-Squared Values, which represent the model's explanatory power in each local wards. Standardized Residuals and the Residual Sum of Squares (RSS) are compiled into their respective DataFrames, providing insights into the model's prediction errors.\n","\n","A new df is created for parameter estimates, showing the impact of each feature, including the intercept, across different locations, reflecting GWR's capability to model spatially-varying relationships. RMSE is calculated and added to the scalar results for a comprehensive overview. The updated scalar results are then displayed in a table format to provide a summary of the model's performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGbf8X-svLY8","scrolled":true},"outputs":[],"source":["# Create a dictionary for scalar results\n","scalar_results_dict = {\n","    \"Metric\": [\"AIC Score\", \"Residual Variance\"],\n","    \"Value\": [gwr_results.aic, gwr_results.sigma2]\n","}\n","\n","# Check if the best model family is Gaussian before adding R-squared and Adjusted R-squared\n","if best_family == 'Gaussian':\n","    scalar_results_dict[\"Metric\"].extend([\"R-squared\", \"Adjusted R-squared\"])\n","    scalar_results_dict[\"Value\"].extend([gwr_results.R2, gwr_results.adj_R2])\n","\n","    # Also, handle Local R-Squared Values only for Gaussian\n","    local_r2_df = pd.DataFrame(gwr_results.localR2, columns=[\"Local R-Squared Values\"])\n","    print(\"\\nLocal R-Squared Values:\")\n","    print(local_r2_df)\n","\n","# Create DataFrame for scalar results\n","scalar_results_df = pd.DataFrame(scalar_results_dict)\n","\n","# Print the scalar results table\n","print(\"GWR Model Scalar Results:\")\n","print(scalar_results_df)\n","\n","# Handle array metrics\n","std_residuals_df = pd.DataFrame(gwr_results.std_res, columns=[\"Standardized Residuals\"])\n","rss_df = pd.DataFrame(gwr_results.RSS, columns=[\"Residual Sum of Squares\"])\n","\n","# Print array metrics tables\n","print(\"\\nStandardized Residuals:\")\n","print(std_residuals_df)\n","print(\"\\nResidual Sum of Squares (RSS):\")\n","print(rss_df)\n","\n","# Create the parameter estimates DataFrame\n","parameter_estimates_df = pd.DataFrame(gwr_results.params)\n","\n","# Set column names for the parameter estimates DataFrame\n","feature_names = ['Intercept'] + selected_features\n","parameter_estimates_df.columns = feature_names\n","\n","# Print the parameter estimates table\n","print(\"\\nParameter Estimates:\")\n","print(parameter_estimates_df)\n","\n","# Calculate RMSE (Root Mean Squared Error)\n","# Access residuals based on model family\n","if best_family in ['Gaussian', 'Poisson']:\n","    residuals = gwr_results.resid_response\n","else: # For Binomial or other families\n","    residuals = gwr_results.resid_pearson\n","\n","rmse = np.sqrt(np.mean(residuals**2))\n","\n","# Add RMSE to the scalar results dictionary\n","scalar_results_dict[\"Metric\"].append(\"RMSE\")\n","scalar_results_dict[\"Value\"].append(rmse)\n","\n","# Update and Print the updated scalar results table\n","scalar_results_df = pd.DataFrame(scalar_results_dict)\n","print(\"Updated GWR Model Scalar Results:\")\n","print(scalar_results_df)\n"]},{"cell_type":"markdown","metadata":{"id":"fmXr8R8HvLY9"},"source":["Now we transform 'geometry' column of a DataFrame into geometric objects using the shapely library, which is essential for spatial analysis. The wkt.loads function is applied to each row in the 'geometry' column to convert Well-Known Text (WKT) format strings into shapely geometric objects. This transformation enables the DataFrame to be converted into a GeoDataFrame, which can then be used for advanced spatial analyses, visualizations, and operations that require geometric computations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Cy2FjnNvLY9"},"outputs":[],"source":["from shapely import wkt\n","print(df['geometry'].head())\n","df['geometry'] = df['geometry'].apply(wkt.loads) #uncomment this line if error occurs\n","\n","# Now create the GeoDataFrame\n","gdf = gpd.GeoDataFrame(df, geometry='geometry')\n"]},{"cell_type":"markdown","metadata":{"id":"xiMwdKYivLY9"},"source":["Below we add results from the GWR model. We check if the GWR model uses a Gaussian family. The parameter estimates from the GWR model, including the y-intercept, are added as new columns in the GeoDataFrame. Additionally, it incorporates key model metrics such as residual variance, standardized residuals, and the AIC score. For Gaussian models, it also adds local R-squared values, Residual Sum of Squares (RSS), and Adjusted R-squared, providing a comprehensive spatial overview of the model's performance at different geographic locations.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8B2ENZEvLY-","scrolled":true},"outputs":[],"source":["from shapely import wkt\n","import geopandas as gpd\n","\n","# Determine model family type\n","is_gaussian = isinstance(gwr_model.family, spglm.family.Gaussian)\n","# Extract the parameter estimates from the GWR results\n","parameter_estimates = gwr_results.params\n","\n","# Adding the y-intercept\n","gdf['Intercept'] = parameter_estimates[:, 0]\n","\n","# Add the GWR results to the GeoDataFrame\n","gdf['residual_variance'] = gwr_results.sigma2\n","gdf['standardized_residuals'] = gwr_results.std_res\n","gdf['aic_score'] = gwr_results.aic\n","\n","# Conditional additions for Gaussian models\n","if is_gaussian:\n","    gdf['local_r2'] = gwr_results.localR2\n","    gdf['residual_sum_of_squares'] = gwr_results.RSS  # Add Residual Sum of Squares\n","    gdf['adjusted_r2'] = gwr_results.adj_R2  # Add Adjusted R-squared"]},{"cell_type":"markdown","metadata":{"id":"039SjIWIvLY-"},"source":["Now to visualize the raw risiduals, we convert the Peach color scheme from Plotly to hexadecimal format, which creates a matplotlib colormap with these hexadecimal colors. The raw residuals are calculated by subtracting the model's predicted values from the actual response values, and these residuals are added to the GeoDataFrame. We use matplotlib to plot the spatial distribution of these raw residuals on a map using the Peach colormap."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OveF3_U3vLY-","scrolled":true},"outputs":[],"source":["\n","import matplotlib.colors as mcolors\n","import plotly.express as px\n","\n","# Get the Peach color scheme from Plotly\n","peach_palette = px.colors.diverging.BrBG\n","\n","# Convert 'rgb()' format to hexadecimal\n","def rgb_to_hex(rgb_str):\n","    rgb = rgb_str.strip('rgb()').split(',')\n","    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]), int(rgb[1]), int(rgb[2]))\n","\n","peach_hex_palette = [rgb_to_hex(color) for color in peach_palette]\n","\n","# Create a colormap using the converted hexadecimal colors\n","peach_cmap = mcolors.LinearSegmentedColormap.from_list(\"Peach\", peach_hex_palette)\n","\n","# Extract the raw residuals from the GWR results\n","# Ensure that raw_residuals is a one-dimensional array\n","raw_residuals = (gwr_results.resid_response.flatten() - gwr_results.predy.flatten())\n","\n","# Add the raw residuals to the GeoDataFrame\n","gdf['raw_residuals'] = raw_residuals\n","\n","# Plotting Raw Residuals using the Peach colormap\n","fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n","gdf.plot(column='raw_residuals', cmap=peach_cmap, legend=True, ax=ax)\n","ax.set_title('GWR Spatial Distribution of Raw Residuals')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"TmBf6E9SvLY-"},"source":["We create more graphs here by converting the RdYlGn (Red-Yellow-Green) color scheme from Plotly into hexadecimal format to create a matplotlib colormap. Using this colormap, we visualize various metrics like residual variance, standardized residuals, AIC score, and for Gaussian models, local R-squared values, Residual Sum of Squares (RSS), and Adjusted R-squared."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_C4gPUUvLY_","scrolled":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","import plotly.express as px\n","\n","# Get the BrBG color scheme from Plotly\n","brbg_palette = px.colors.diverging.BrBG\n","\n","# Convert 'rgb()' format to hexadecimal\n","def rgb_to_hex(rgb_str):\n","    rgb = rgb_str.strip('rgb()').split(',')\n","    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]), int(rgb[1]), int(rgb[2]))\n","\n","brbg_hex_palette = [rgb_to_hex(color) for color in brbg_palette]\n","\n","# Create a colormap using the converted hexadecimal colors\n","brbg_cmap = mcolors.LinearSegmentedColormap.from_list(\"BrBG\", brbg_hex_palette)\n","\n","# Plotting Residual Variance\n","fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n","gdf.plot(column='residual_variance', cmap=brbg_cmap, legend=True, ax=ax)\n","ax.set_title('GWR Spatial Distribution of Residual Variance')\n","plt.show()\n","\n","# Plotting Standardized Residuals\n","fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n","gdf.plot(column='standardized_residuals', cmap='BrBG', legend=True, ax=ax,\n","         vmin=-4, vmax=4)  # Set the range from -4 to 4\n","ax.set_title('GWR Spatial Distribution of Standardized Residuals')\n","plt.show()\n","# Plotting AIC Score\n","fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n","gdf.plot(column='aic_score', cmap=brbg_cmap, legend=True, ax=ax)\n","ax.set_title('GWR Spatial Distribution of AIC Score')\n","plt.show()\n","\n","# Conditional plotting for Gaussian models\n","if is_gaussian:\n","    # Plotting Local R-Squared\n","    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n","    gdf.plot(column='local_r2', cmap=brbg_cmap, legend=True, ax=ax)\n","    ax.set_title('GWR Spatial Distribution of Local R-Squared')\n","    plt.show()\n","\n","    # Plotting Residual Sum of Squares\n","    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n","    gdf.plot(column='residual_sum_of_squares', cmap=brbg_cmap, legend=True, ax=ax)\n","    ax.set_title('GWR Spatial Distribution of Residual Sum of Squares')\n","    plt.show()\n","\n","    # Plotting Adjusted R-Squared\n","    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n","    gdf.plot(column='adjusted_r2', cmap=brbg_cmap, legend=True, ax=ax)\n","    ax.set_title('GWR Spatial Distribution of Adjusted R-Squared')\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"kTgNRtltvLY_"},"source":["Finally, we create a Dash app. We set up a dropdown menu and a map plot in the app layout, using the previously mentioned GWR metrics and the local coefficients of the features used in the GWR model. The app allows users to select a metric from the dropdown, and the map will update to display the spatial distribution of the selected metric using Plotly Express, a plotting library that works seamlessly with Dash. This interactivity makes it easy to explore and understand the spatial aspects of the GWR model's results, providing a user-friendly interface for analyzing complex geospatial data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztZN9EBVbeVh"},"outputs":[],"source":["import dash\n","from dash import dcc, html, Input, Output\n","import plotly.express as px\n","\n","# Initialize the Dash app\n","app = dash.Dash(__name__)\n","\n","# GWR metrics with updated column names and parameter estimates\n","gwr_metrics = {\n","    'Residual Variance': 'residual_variance',\n","    'Standardized Residuals': 'standardized_residuals',\n","    'AIC Score': 'aic_score'\n","}\n","\n","# Add Gaussian-specific metrics if applicable\n","if is_gaussian:\n","    gwr_metrics['Local R-Squared'] = 'local_r2'\n","    gwr_metrics['Residual Sum Squares'] = 'residual_sum_of_squares'\n","    gwr_metrics['Adjusted R-Squared'] = 'adjusted_r2'\n","\n","# Layout of the app\n","app.layout = html.Div([\n","    dcc.Dropdown(\n","        id='metric-dropdown',\n","        options=[{'label': k, 'value': v} for k, v in gwr_metrics.items()],\n","        value='local_r2'  # Default metric\n","    ),\n","    dcc.Graph(id='gwr-map', style={'height': '85vh', 'width': '100%'})\n","])\n","\n","# Callback to update the map\n","@app.callback(\n","    Output('gwr-map', 'figure'),\n","    Input('metric-dropdown', 'value')\n",")\n","def update_map(selected_metric):\n","    fig = px.scatter_mapbox(\n","        gdf,\n","        lat=\"latitude\",\n","        lon=\"longitude\",\n","        hover_name='areaName',  # Replace with the correct column name\n","        color=selected_metric,\n","        color_continuous_scale=px.colors.diverging.BrBG,\n","        size_max=20,\n","        zoom=5,\n","        mapbox_style=\"carto-darkmatter\"\n","    )\n","    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, autosize=True)\n","    return fig\n","\n","# Run the app\n","if __name__ == '__main__':\n","    app.run_server(debug=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRYPu8EAvLZA"},"outputs":[],"source":["import dash\n","from dash import dcc, html, Input, Output\n","import plotly.express as px\n","import pandas as pd\n","\n","# Assuming df_coeffs is your DataFrame with latitude, longitude, and coefficients\n","# Example structure: 'latitude', 'longitude', 'professional_coeff', 'management_coeff', ...\n","\n","# List of features for which you have coefficients\n","selected_features = ['professional', 'management', 'v0', 'dep1', 'wBritish', 'semiDetached', 'level3', 'whiteAndAsian', 'L8_L9', 'L15']\n","\n","# Create a DataFrame for coordinates and coefficients\n","df_coeffs = pd.DataFrame(coords, columns=['latitude', 'longitude'])\n","for i, feature in enumerate(selected_features, start=1):  # Start from 1 to skip intercept\n","    df_coeffs[f'{feature}_coeff'] = local_params[:, i]\n","\n","# Initialize the Dash app\n","app = dash.Dash(__name__)\n","\n","# Layout of the app\n","app.layout = html.Div([\n","    dcc.Dropdown(\n","        id='feature-dropdown',\n","        options=[{'label': f'Coefficient of {feature}', 'value': f'{feature}_coeff'} for feature in selected_features],\n","        value=f'{selected_features[0]}_coeff'  # Default to the first feature's coefficient\n","    ),\n","    dcc.Graph(id='gwr-coeff-map', style={'height': '85vh', 'width': '100%'})\n","])\n","\n","# Callback to update the map\n","@app.callback(\n","    Output('gwr-coeff-map', 'figure'),\n","    Input('feature-dropdown', 'value')\n",")\n","def update_map(selected_coeff):\n","    fig = px.scatter_mapbox(\n","        df_coeffs,\n","        lat=\"latitude\",\n","        lon=\"longitude\",\n","        color=selected_coeff,\n","        color_continuous_scale=px.colors.diverging.BrBG,\n","        size_max=15,\n","        zoom=5,\n","        mapbox_style=\"carto-darkmatter\"\n","    )\n","    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, autosize=True)\n","    return fig\n","\n","# Run the app\n","if __name__ == '__main__':\n","    app.run_server(debug=True)\n"]},{"cell_type":"markdown","metadata":{"id":"jv9vw9h3vLZB"},"source":["Our notebook for GWR ends here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1JVLtchvLZB"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}